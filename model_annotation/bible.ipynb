{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\nicho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'negative', 'score': 0.8345967531204224},\n",
       "  {'label': 'neutral', 'score': 0.1521468460559845},\n",
       "  {'label': 'positive', 'score': 0.013256409205496311}]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"TEST BLOCK\"\"\"\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    return_all_scores=True,\n",
    ")\n",
    "classifier(\n",
    "    \"Make ready to slaughter his sons for the guilt of their fathers; Lest they rise and posses the earth, and fill the breadth of the world with tyrants.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd41e099e8a43ceabfd2837af27cf60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8542f54e396048d4848c32192611517c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c1f9772fa24a20ade10dda8fb1086c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69b505bc6874926a9b54be60d013f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb53acac7684ea79f7d999702504c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/school/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    return_all_scores=False,\n",
    ")\n",
    "\n",
    "\n",
    "def label_to_sentiment(label):\n",
    "    \"\"\"based on the key from the manual annotations\"\"\"\n",
    "    if label == \"neutral\":\n",
    "        return 1\n",
    "    elif label == \"positive\":\n",
    "        return 2\n",
    "    elif label == \"negative\":\n",
    "        return 3\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process(row):\n",
    "    text = row[\"text\"]\n",
    "    result = classifier(text)\n",
    "    sentiment = result[0][\"label\"]\n",
    "    confidence = result[0][\"score\"]\n",
    "    sentiment_value = label_to_sentiment(sentiment)\n",
    "    return {\n",
    "        \"chunk\": row[\"chunk\"],\n",
    "        \"start_citation\": row[\"start_citation\"],\n",
    "        \"text\": text,\n",
    "        \"sentiment\": sentiment_value,\n",
    "        \"confidence\": confidence,\n",
    "    }\n",
    "\n",
    "\n",
    "# def annotate(infile):\n",
    "# '''testing function on one file instead of a dictionary'''\n",
    "#     outfile = f\"{infile[:-4]}_out.csv\"  # output files are named \"<infile>_out.csv\"\n",
    "#     with open(infile, mode='r', newline='', encoding='utf-8') as file:\n",
    "#         reader = csv.DictReader(file)\n",
    "#         with open(outfile, mode='w', newline='', encoding='utf-8') as out_csv:\n",
    "#             fields = ['chunk', 'start_citation', 'text', 'sentiment', 'confidence']\n",
    "#             writer = csv.DictWriter(out_csv, fieldnames=fields)\n",
    "#             writer.writeheader()\n",
    "#             for row in reader:\n",
    "#                 writer.writerow(process(row))\n",
    "\n",
    "#     print(f\"Sentiment analysis completed for {infile}. Results exported to {outfile}\")\n",
    "\n",
    "\n",
    "def annotate(bible_paths):\n",
    "    for bible, infile in bible_paths.items():\n",
    "        outfile = f\"{bible}_out.csv\"  # output files are named \"<bible>_out.csv\"\n",
    "        with open(infile, mode=\"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            with open(outfile, mode=\"w\", newline=\"\", encoding=\"utf-8\") as out_csv:\n",
    "                fields = [\"chunk\", \"start_citation\", \"text\", \"sentiment\", \"confidence\"]\n",
    "                writer = csv.DictWriter(out_csv, fieldnames=fields)\n",
    "                writer.writeheader()\n",
    "                for row in reader:\n",
    "                    try:\n",
    "                        writer.writerow(process(row))\n",
    "                    except RuntimeError as e:\n",
    "                        print(f\"RuntimeError occurred while processing row: {row}\")\n",
    "                        print(f\"Error message: {e}\")\n",
    "                        # if we hit this block, just set sentiment score and confidence to 0\n",
    "                        writer.writerow(\n",
    "                            {\n",
    "                                \"chunk\": row[\"chunk\"],\n",
    "                                \"start_citation\": row[\"start_citation\"],\n",
    "                                \"text\": row[\"text\"],\n",
    "                                \"sentiment\": 0,\n",
    "                                \"confidence\": 0.0,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "        print(f\"Sentiment analysis completed for {infile}. Results exported to {outfile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis completed for ../data/bibles_chunked/kjv.csv. Results exported to kjv_out.csv\n"
     ]
    }
   ],
   "source": [
    "# uncomment paths to run the model\n",
    "bible_paths = {\n",
    "    # \"asv\": \"../data/bibles_chunked/asv.csv\",\n",
    "    # \"fbv\": \"../data/bibles_chunked/fbv.csv\",\n",
    "    # \"web\": \"../data/bibles_chunked/web.csv\", # looks like chunk 7909 might be causing a runtime error bc its too big, need to fix\n",
    "    # \"wmb\": \"../data/bibles_chunked/wmb.csv\",\n",
    "    # \"kjv\": \"../data/bibles_chunked/kjv.csv\"\n",
    "}\n",
    "\n",
    "annotate(bible_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
