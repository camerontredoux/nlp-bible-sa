{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'negative', 'score': 0.8345967531204224},\n",
       "  {'label': 'neutral', 'score': 0.1521468460559845},\n",
       "  {'label': 'positive', 'score': 0.013256409205496311}]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"TEST BLOCK\"\"\"\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    return_all_scores=True,\n",
    ")\n",
    "classifier(\n",
    "    \"Make ready to slaughter his sons for the guilt of their fathers; Lest they rise and posses the earth, and fill the breadth of the world with tyrants.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    return_all_scores=False,\n",
    ")\n",
    "\n",
    "\n",
    "def label_to_sentiment(label):\n",
    "    \"\"\"based on the key from the manual annotations\"\"\"\n",
    "    if label == \"neutral\":\n",
    "        return 1\n",
    "    elif label == \"positive\":\n",
    "        return 2\n",
    "    elif label == \"negative\":\n",
    "        return 3\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process(row):\n",
    "    \"\"\"parses model output to fill in sentiment/confidence scores for each row\"\"\"\n",
    "\n",
    "    text = row[\"text\"]\n",
    "    result = classifier(text)\n",
    "    sentiment = result[0][\"label\"]\n",
    "    confidence = result[0][\"score\"]\n",
    "    sentiment_value = label_to_sentiment(sentiment)\n",
    "    return {\n",
    "        \"chunk\": row[\"chunk\"],\n",
    "        \"start_citation\": row[\"start_citation\"],\n",
    "        \"text\": text,\n",
    "        \"sentiment\": sentiment_value,\n",
    "        \"confidence\": confidence,\n",
    "    }\n",
    "\n",
    "\n",
    "# def annotate(infile):\n",
    "# '''testing function on one file instead of a dictionary'''\n",
    "#     outfile = f\"{infile[:-4]}_out.csv\"  # output files are named \"<infile>_out.csv\"\n",
    "#     with open(infile, mode='r', newline='', encoding='utf-8') as file:\n",
    "#         reader = csv.DictReader(file)\n",
    "#         with open(outfile, mode='w', newline='', encoding='utf-8') as out_csv:\n",
    "#             fields = ['chunk', 'start_citation', 'text', 'sentiment', 'confidence']\n",
    "#             writer = csv.DictWriter(out_csv, fieldnames=fields)\n",
    "#             writer.writeheader()\n",
    "#             for row in reader:\n",
    "#                 writer.writerow(process(row))\n",
    "\n",
    "#     print(f\"Sentiment analysis completed for {infile}. Results exported to {outfile}\")\n",
    "\n",
    "\n",
    "def annotate(bible_paths):\n",
    "    for bible, infile in bible_paths.items():\n",
    "        outfile = f\"{bible}_out.csv\"  # output files are named \"<bible>_out.csv\"\n",
    "        with open(infile, mode=\"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            with open(outfile, mode=\"w\", newline=\"\", encoding=\"utf-8\") as out_csv:\n",
    "                fields = [\"chunk\", \"start_citation\", \"text\", \"sentiment\", \"confidence\"]\n",
    "                writer = csv.DictWriter(out_csv, fieldnames=fields)\n",
    "                writer.writeheader()  # generate new columns based on field names\n",
    "                for row in reader:\n",
    "                    # added try-except clause to handle runtime error regarding input text length in web.csv\n",
    "                    # tensorflow has a maximum tensor size that this input text was exceeding.\n",
    "                    try:\n",
    "                        writer.writerow(process(row))\n",
    "                    except RuntimeError as e:\n",
    "                        print(f\"RuntimeError occurred while processing row: {row}\")\n",
    "                        print(f\"Error message: {e}\")\n",
    "                        # if we hit this block, just set sentiment score and confidence to 0\n",
    "                        writer.writerow(\n",
    "                            {\n",
    "                                \"chunk\": row[\"chunk\"],\n",
    "                                \"start_citation\": row[\"start_citation\"],\n",
    "                                \"text\": row[\"text\"],\n",
    "                                \"sentiment\": 0,\n",
    "                                \"confidence\": 0.0,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "        print(f\"Sentiment analysis completed for {infile}. Results exported to {outfile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment paths to run the model - recomment as you go, otherwise progress will be overwritten\n",
    "bible_paths = {\n",
    "    # \"asv\": \"../data/bibles_chunked/asv.csv\",\n",
    "    # \"fbv\": \"../data/bibles_chunked/fbv.csv\",\n",
    "    # \"web\": \"../data/bibles_chunked/web.csv\", # looks like chunk 7909 might be causing a runtime error bc its too big, need to fix\n",
    "    # \"wmb\": \"../data/bibles_chunked/wmb.csv\",\n",
    "    # \"kjv\": \"../data/bibles_chunked/kjv.csv\"\n",
    "}\n",
    "\n",
    "# comment when done\n",
    "# annotate(bible_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
